{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdWeS1_ViEo6",
        "outputId": "a20af866-72e2-43cf-a6de-81fd490e661c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5qFfY1biBoC"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from keras import models\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, TimeDistributed, Dense, ConvLSTM2D, MultiHeadAttention, Flatten, MaxPooling3D, BatchNormalization, Dropout\n",
        "from tensorflow.keras.metrics import AUC\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "import imageio\n",
        "from IPython import display\n",
        "from urllib import request\n",
        "from tensorflow_docs.vis import embed\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RESNET pretrained\n",
        "pretrained_model = tf.keras.applications.ResNet50(include_top=False,\n",
        "                                                  input_shape=(224, 224, 3),\n",
        "                                                  pooling='avg')\n",
        "\n",
        "# buang avg pool layer\n",
        "gap_layer_name = 'avg_pool'\n",
        "gap_layer_index = None\n",
        "\n",
        "for i, layer in enumerate(pretrained_model.layers):\n",
        "    if layer.name == gap_layer_name:\n",
        "        gap_layer_index = i\n",
        "        break\n",
        "\n",
        "\n",
        "if gap_layer_index is not None:\n",
        "    model_without_gap = tf.keras.Model(inputs=pretrained_model.input, outputs=pretrained_model.layers[gap_layer_index - 1].output)\n",
        "\n",
        "else:\n",
        "    print(\"GAP layer not found.\")"
      ],
      "metadata": {
        "id": "lfMF_SL3iLjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_input_shape = (20, 224, 224, 3)\n",
        "\n",
        "video_input = tf.keras.Input(shape=video_input_shape)\n",
        "time_distributed = TimeDistributed(model_without_gap)(video_input)\n",
        "\n",
        "conv_lstm_output = ConvLSTM2D(filters=256, kernel_size=(3, 3), padding=\"same\", return_sequences=True)(time_distributed)\n",
        "\n",
        "mhsa_output = MultiHeadAttention(num_heads=8, key_dim=256, value_dim=256)(conv_lstm_output, conv_lstm_output)\n",
        "# attention_time = TimeDistributed(tf.keras.layers.Lambda(lambda x: x))(mhsa_output)\n",
        "\n",
        "conv_lstm_output2 = ConvLSTM2D(filters=256, kernel_size=(3, 3), padding=\"same\", return_sequences=True)(mhsa_output)\n",
        "\n",
        "maxpool3d = MaxPooling3D(pool_size=(1,2,2))(conv_lstm_output2)\n",
        "\n",
        "flattened = Flatten()(maxpool3d)\n",
        "\n",
        "dense_1 = Dense(1000, activation=\"relu\")(flattened)\n",
        "dense_2 = Dense(256, activation=\"relu\")(dense_1)\n",
        "dense_3 = Dense(10, activation=\"relu\")(dense_2)\n",
        "dense_4 = Dense(2, activation=\"softmax\")(dense_3)\n",
        "\n",
        "# Create the model\n",
        "model_no_pretrain = tf.keras.Model(inputs=video_input, outputs=dense_4)\n",
        "\n",
        "model_no_pretrain.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE-OJUdjiMsi",
        "outputId": "e11bc36a-9779-4911-b065-0b5bfbb459df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None, 20, 224, 224, 3)]    0         []                            \n",
            "                                                                                                  \n",
            " time_distributed_2 (TimeDi  (None, 20, 7, 7, 2048)       2358771   ['input_6[0][0]']             \n",
            " stributed)                                               2                                       \n",
            "                                                                                                  \n",
            " conv_lstm2d_4 (ConvLSTM2D)  (None, 20, 7, 7, 256)        2123468   ['time_distributed_2[0][0]']  \n",
            "                                                          8                                       \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (Mu  (None, 20, 7, 7, 256)        2103552   ['conv_lstm2d_4[0][0]',       \n",
            " ltiHeadAttention)                                                   'conv_lstm2d_4[0][0]']       \n",
            "                                                                                                  \n",
            " conv_lstm2d_5 (ConvLSTM2D)  (None, 20, 7, 7, 256)        4719616   ['multi_head_attention_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling3d_2 (MaxPoolin  (None, 20, 3, 3, 256)        0         ['conv_lstm2d_5[0][0]']       \n",
            " g3D)                                                                                             \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 46080)                0         ['max_pooling3d_2[0][0]']     \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 1000)                 4608100   ['flatten_2[0][0]']           \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 256)                  256256    ['dense_8[0][0]']             \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 10)                   2570      ['dense_9[0][0]']             \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 2)                    22        ['dense_10[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 97985416 (373.78 MB)\n",
            "Trainable params: 97932296 (373.58 MB)\n",
            "Non-trainable params: 53120 (207.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "lr = 1e-6"
      ],
      "metadata": {
        "id": "D919k0VuiPNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_no_pretrain.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr),\n",
        "              metrics=['accuracy', AUC(multi_label=False)])"
      ],
      "metadata": {
        "id": "7DG5vl-jiQUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtPcG065rYS_",
        "outputId": "d356c67f-16e4-4942-c257-c9e0e1f8e53f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_no_pretrain.load_weights('/content/drive/MyDrive/model_no_pt_weights.h5')"
      ],
      "metadata": {
        "id": "qGrcu-rGiTM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def video2frame(filepath, resize=(224,224)):\n",
        "\n",
        "    cap = cv2.VideoCapture(filepath)\n",
        "    # num of frames\n",
        "    len_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    # print(len_frames)\n",
        "    len_frames = int(len_frames)\n",
        "    frames = []\n",
        "    try:\n",
        "        for i in range(len_frames):\n",
        "            _, frame = cap.read()\n",
        "            frame = cv2.resize(frame, resize, interpolation=cv2.INTER_AREA)\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frame = np.reshape(frame, (224, 224, 3))\n",
        "            frames.append(frame)\n",
        "    except:\n",
        "        print(\"error: \", filepath, len_frames, i)\n",
        "    finally:\n",
        "        frames = np.array(frames)\n",
        "        cap.release()\n",
        "\n",
        "    flows = calc_optical_flow(frames)\n",
        "\n",
        "    result = np.zeros((len(flows), 224, 224, 5))\n",
        "    result[..., :3] = frames\n",
        "    result[..., 3:] = flows\n",
        "\n",
        "    frames = uniform_sampling(result, 20)\n",
        "    return frames\n",
        "\n",
        "\n",
        "def frame_difference(frames):\n",
        "    num_frames = len(frames)\n",
        "    out = []\n",
        "    for i in range(num_frames - 1):\n",
        "        out.append(cv2.subtract(frames[i + 1], frames[i]))\n",
        "\n",
        "    return np.array(out)\n",
        "\n",
        "\n",
        "def uniform_sampling(frames, target_frames=10):\n",
        "    num_frames = len(frames)\n",
        "    skip_frames = num_frames//target_frames\n",
        "    out = []\n",
        "\n",
        "    for i in range(target_frames):\n",
        "        out.append(frames[i * skip_frames])\n",
        "\n",
        "    return np.array(out)\n",
        "\n",
        "\n",
        "def flow_to_color(video):\n",
        "    rgb_flows = []\n",
        "\n",
        "    cap = cv2.VideoCapture(video)\n",
        "\n",
        "    ret, first_frame = cap.read()\n",
        "\n",
        "    prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Creates an image filled with zero intensities with the same dimensions as the frame\n",
        "    mask = np.zeros_like(first_frame)\n",
        "\n",
        "    # Sets image saturation to maximum\n",
        "    mask[..., 1] = 255\n",
        "\n",
        "    while (cap.isOpened()):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Calculates dense optical flow by Farneback method\n",
        "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray,\n",
        "                                           None,\n",
        "                                           0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "        # Computes the magnitude and angle of the 2D vectors\n",
        "        magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "\n",
        "        # Sets image hue according to the optical flow direction\n",
        "        mask[..., 0] = angle * 180 / np.pi / 2\n",
        "\n",
        "        # Sets image value according to the optical flow magnitude (normalized)\n",
        "        mask[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
        "\n",
        "        # Converts HSV to RGB (BGR) color representation\n",
        "        rgb = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "        resized_rgb = cv2.resize(rgb, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "        rgb_flows.append(resized_rgb)\n",
        "\n",
        "        prev_gray = gray\n",
        "\n",
        "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        #     break\n",
        "\n",
        "    cap.release()\n",
        "    # rgb_flows.append(np.zeros((224, 224, 3)))\n",
        "    # cv2.destroyAllWindows()\n",
        "\n",
        "    return np.array(rgb_flows)\n",
        "\n",
        "\n",
        "\n",
        "def Save2Npy(file_dir, save_dir):\n",
        "    \"\"\"Transfer all the videos and save them into specified directory\n",
        "    Args:\n",
        "        file_dir: source folder of target videos\n",
        "        save_dir: destination folder of output .npy files\n",
        "    \"\"\"\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    # List the files\n",
        "    videos = os.listdir(file_dir)\n",
        "    for v in tqdm(videos):\n",
        "        # Split video name\n",
        "        video_name = v.split('.')[0]\n",
        "        # Get src\n",
        "        video_path = os.path.join(file_dir, v)\n",
        "        # Get dest\n",
        "        save_path = os.path.join(save_dir, video_name + '.npy')\n",
        "        # Load and preprocess video\n",
        "        data = video2frame(video_path, resize=(224, 224))\n",
        "        data = np.uint8(data)\n",
        "        # Save as .npy file\n",
        "        np.save(save_path, data)\n",
        "\n",
        "    return None\n",
        "\n",
        "def Save2Npy2(file_dir, save_dir):\n",
        "    \"\"\"Transfer all the videos and save them into specified directory\n",
        "    Args:\n",
        "        file_dir: source folder of target videos\n",
        "        save_dir: destination folder of output .npy files\n",
        "    \"\"\"\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    # List the files\n",
        "    videos = os.listdir(file_dir)\n",
        "    for v in tqdm(videos):\n",
        "        # Split video name\n",
        "        video_name = v.split('.')[0]\n",
        "        # Get src\n",
        "        video_path = os.path.join(file_dir, v)\n",
        "        # Get dest\n",
        "        save_path = os.path.join(save_dir, video_name + '.npy')\n",
        "        # Load and preprocess video\n",
        "        data = flow_to_color(video_path)\n",
        "        data = np.uint8(data)\n",
        "        # Save as .npy file\n",
        "        np.save(save_path, data)\n",
        "\n",
        "    return None\n",
        "\n",
        "def calc_optical_flow(frames):\n",
        "    gray_frames = [cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY) for frame in frames]\n",
        "\n",
        "    dense_flow = []\n",
        "\n",
        "    for i in range(1, len(gray_frames)):\n",
        "        prev_frame = gray_frames[i-1]\n",
        "        cur_frame = gray_frames[i]\n",
        "\n",
        "        flow = cv2.calcOpticalFlowFarneback(prev_frame, cur_frame, None, 0.5, 3, 15, 3, 5, 1.2, cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
        "        flow[..., 0] -= np.mean(flow[..., 0])\n",
        "        flow[..., 1] -= np.mean(flow[..., 1])\n",
        "        # normalize\n",
        "        flow[..., 0] = cv2.normalize(flow[..., 0], None, 0, 255, cv2.NORM_MINMAX)\n",
        "        flow[..., 1] = cv2.normalize(flow[..., 1], None, 0, 255, cv2.NORM_MINMAX)\n",
        "\n",
        "        dense_flow.append(flow)\n",
        "    # Padding the last frame as empty array\n",
        "    dense_flow.append(np.zeros((224, 224, 2)))\n",
        "\n",
        "    return np.array(dense_flow, dtype=np.float32)\n"
      ],
      "metadata": {
        "id": "2hbKcFuar81k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mypredict(model, video_path):\n",
        "  testing_frame = video2frame(video_path)\n",
        "  coba_frame = testing_frame[:, :, :, :3]\n",
        "  coba_frame = coba_frame//255.0\n",
        "  coba_frame = np.reshape(coba_frame, (1, 20, 224, 224, 3))\n",
        "  pred = model_no_pretrain.predict(coba_frame)\n",
        "  predicted_class = np.argmax(pred, axis=-1)\n",
        "  return pred, predicted_class"
      ],
      "metadata": {
        "id": "BHXVjcr2p3MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coba2_pred, coba2_class = mypredict(model_no_pretrain, \"/content/t_n006_converted.avi\")\n",
        "coba2_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dW3MO6MsExP",
        "outputId": "4dded307-27a5-46e2-ba24-54645514df75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 10s 10s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coba2_pred, coba2_class = mypredict(model_no_pretrain, \"/content/t_n006_converted.avi\")\n",
        "coba2_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrZYfFx9sIpr",
        "outputId": "d224b9cc-dd0d-47a8-ff21-59a4a8a21823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 7s 7s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JlRTvN0A6Nfn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}