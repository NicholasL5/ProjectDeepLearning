{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from keras import models\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, TimeDistributed, Dense, ConvLSTM2D, MultiHeadAttention, Flatten, MaxPooling3D\n",
        "\n",
        "import os\n",
        "import random\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "gIzK_wTkQ_1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfyalOmb7fEe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b1a8bdd-0be4-4468-e8ee-bcc77020c43f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DIR = \"drive/MyDrive/dataset\""
      ],
      "metadata": {
        "id": "IUm9lSjbR4A8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cek\n",
        "os.listdir(DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ4rDqiHRYS4",
        "outputId": "88dade08-0f50-486d-fd90-7df63466efae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'val']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"file train/fight: \",len(os.listdir(DIR+\"/train/Fight\")))\n",
        "print(\"file train/nonfight:\", len(os.listdir(DIR+\"/train/NonFight\")))\n",
        "print(\"file val/fight: \", len(os.listdir(DIR+\"/val/Fight\")))\n",
        "print(\"file val/nonfight: \", len(os.listdir(DIR+\"/val/NonFight\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcKZ2TrkRcqv",
        "outputId": "0cff4d02-1165-4c6c-f411-3478e26fc645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file train/fight:  800\n",
            "file train/nonfight: 800\n",
            "file val/fight:  200\n",
            "file val/nonfight:  200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FrameGenerator:\n",
        "    def __init__(self, path, training=False):\n",
        "        \"\"\" Returns a set of frames with their associated label.\n",
        "          Args:\n",
        "            path: Video file paths.\n",
        "            n_frames: Number of frames.\n",
        "            training: Boolean to determine if training dataset is being created.\n",
        "        \"\"\"\n",
        "        self.path = path\n",
        "\n",
        "        self.training = training\n",
        "        self.class_names = ['NonFight', 'Fight']\n",
        "        self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n",
        "\n",
        "    def get_files_and_class_names(self):\n",
        "        if self.training:\n",
        "            video_paths = list(self.path.glob('Fight/*.npy'))[:160] + list(self.path.glob('NonFight/*.npy'))[:160]\n",
        "        else:\n",
        "            video_paths = list(self.path.glob('Fight/*.npy'))[:40] + list(self.path.glob('NonFight/*.npy'))[:40]\n",
        "        classes = [p.parent.name for p in video_paths]\n",
        "\n",
        "        return video_paths, classes\n",
        "\n",
        "    def __call__(self):\n",
        "        video_paths, classes = self.get_files_and_class_names()\n",
        "\n",
        "        pairs = list(zip(video_paths, classes))\n",
        "\n",
        "        if self.training:\n",
        "            random.shuffle(pairs)\n",
        "\n",
        "        for path, name in pairs:\n",
        "            video_frames = self.read_npy_file(path)\n",
        "            label = self.class_ids_for_name[name]\n",
        "            yield video_frames, label\n",
        "\n",
        "\n",
        "    def read_npy_file(self, path):\n",
        "        data = np.load(path)\n",
        "        data = np.float32(data)\n",
        "        data = data/255.0\n",
        "        return data"
      ],
      "metadata": {
        "id": "ApIaO7jHSCKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = Path(DIR).joinpath(\"train\").with_suffix('')\n",
        "test_file = Path(DIR).joinpath(\"val\").with_suffix('')\n",
        "train_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX9lWQv1SrOq",
        "outputId": "142f8cab-d764-4dfd-f1c4-b80ad6f9196d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('drive/MyDrive/dataset/train')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fg = FrameGenerator(train_file, training=True)\n",
        "\n",
        "# test\n",
        "frames, label = next(fg())\n",
        "print(fg)\n",
        "print(f\"Shape: {frames.shape}\")\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue80u1S9S6RK",
        "outputId": "73e4bf26-452d-4c54-ba2b-0ee45183ed69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.FrameGenerator object at 0x7d5c6e1e4c40>\n",
            "Shape: (21, 224, 224, 3)\n",
            "Label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# buat tf.data.Dataset\n",
        "batch_size = 3\n",
        "\n",
        "output_signature = (tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),\n",
        "                    tf.TensorSpec(shape=(), dtype=tf.int16))\n",
        "\n",
        "train_ds = tf.data.Dataset.from_generator(FrameGenerator(train_file, training=True),\n",
        "                                          output_signature=output_signature)\n",
        "\n",
        "\n",
        "test_ds = tf.data.Dataset.from_generator(FrameGenerator(test_file),\n",
        "                                          output_signature=output_signature)\n"
      ],
      "metadata": {
        "id": "QKjW4hwATMCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.batch(batch_size)\n",
        "test_ds = test_ds.batch(batch_size)"
      ],
      "metadata": {
        "id": "t-2qtNQVBX36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size = AUTOTUNE)"
      ],
      "metadata": {
        "id": "xhKc4iLUBUkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test data\n",
        "for frames, labels in train_ds.take(10):\n",
        "    print(labels)\n",
        "\n",
        "print(f\"Shape: {frames.shape}\")\n",
        "print(f\"Label: {labels.shape}\")"
      ],
      "metadata": {
        "id": "3fy39rh-Td9M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb30a12-def4-47f5-af7d-1ce0325c748d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 0 1], shape=(3,), dtype=int16)\n",
            "tf.Tensor([1 0 0], shape=(3,), dtype=int16)\n",
            "tf.Tensor([0 1 1], shape=(3,), dtype=int16)\n",
            "tf.Tensor([1 0 1], shape=(3,), dtype=int16)\n",
            "tf.Tensor([1 0 1], shape=(3,), dtype=int16)\n",
            "tf.Tensor([0 0 0], shape=(3,), dtype=int16)\n",
            "tf.Tensor([1 0 1], shape=(3,), dtype=int16)\n",
            "tf.Tensor([1 1 1], shape=(3,), dtype=int16)\n",
            "tf.Tensor([1 0 0], shape=(3,), dtype=int16)\n",
            "tf.Tensor([1 1 0], shape=(3,), dtype=int16)\n",
            "Shape: (3, 21, 224, 224, 3)\n",
            "Label: (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RESNET pretrained\n",
        "pretrained_model = tf.keras.applications.ResNet50(include_top=False,\n",
        "                                                  input_shape=(224, 224, 3),\n",
        "                                                  pooling='avg',\n",
        "                                                  weights='imagenet')"
      ],
      "metadata": {
        "id": "UfvQg8lJThkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# buang avg pool layer\n",
        "gap_layer_name = 'avg_pool'\n",
        "gap_layer_index = None\n",
        "\n",
        "for i, layer in enumerate(pretrained_model.layers):\n",
        "    if layer.name == gap_layer_name:\n",
        "        gap_layer_index = i\n",
        "        break\n",
        "\n",
        "\n",
        "if gap_layer_index is not None:\n",
        "    model_without_gap = tf.keras.Model(inputs=pretrained_model.input, outputs=pretrained_model.layers[gap_layer_index - 1].output)\n",
        "\n",
        "else:\n",
        "    print(\"GAP layer not found.\")"
      ],
      "metadata": {
        "id": "0ZL4cxrdTyt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_input_shape = (21, 224, 224, 3)\n",
        "\n",
        "video_input = tf.keras.Input(shape=video_input_shape)\n",
        "time_distributed = TimeDistributed(model_without_gap)(video_input)\n",
        "\n",
        "conv_lstm_output = ConvLSTM2D(filters=256, kernel_size=(3, 3), padding=\"same\", return_sequences=True)(time_distributed)\n",
        "\n",
        "mhsa_output = MultiHeadAttention(num_heads=8, key_dim=256, value_dim=256)(conv_lstm_output, conv_lstm_output)\n",
        "attention_time = TimeDistributed(tf.keras.layers.Lambda(lambda x: x))(mhsa_output)\n",
        "\n",
        "conv_lstm_output2 = ConvLSTM2D(filters=256, kernel_size=(3, 3), padding=\"same\", return_sequences=True)(attention_time)\n",
        "\n",
        "maxpool3d = MaxPooling3D(pool_size=(1,2,2))(conv_lstm_output2)\n",
        "\n",
        "flattened = Flatten()(maxpool3d)\n",
        "\n",
        "dense_1 = Dense(1000, activation=\"relu\")(flattened)\n",
        "dense_2 = Dense(256, activation=\"relu\")(dense_1)\n",
        "dense_3 = Dense(10, activation=\"relu\")(dense_2)\n",
        "dense_4 = Dense(2, activation=\"softmax\")(dense_3)\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.Model(inputs=video_input, outputs=dense_4)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "4OdaoZzqT5EF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11be701b-a19d-4e01-f554-e9135b90dd5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None, 21, 224, 224, 3)]    0         []                            \n",
            "                                                                                                  \n",
            " time_distributed_4 (TimeDi  (None, 21, 7, 7, 2048)       2358771   ['input_6[0][0]']             \n",
            " stributed)                                               2                                       \n",
            "                                                                                                  \n",
            " conv_lstm2d_4 (ConvLSTM2D)  (None, 21, 7, 7, 256)        2123468   ['time_distributed_4[0][0]']  \n",
            "                                                          8                                       \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (Mu  (None, 21, 7, 7, 256)        2103552   ['conv_lstm2d_4[0][0]',       \n",
            " ltiHeadAttention)                                                   'conv_lstm2d_4[0][0]']       \n",
            "                                                                                                  \n",
            " time_distributed_5 (TimeDi  (None, 21, 7, 7, 256)        0         ['multi_head_attention_2[0][0]\n",
            " stributed)                                                         ']                            \n",
            "                                                                                                  \n",
            " conv_lstm2d_5 (ConvLSTM2D)  (None, 21, 7, 7, 256)        4719616   ['time_distributed_5[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling3d_2 (MaxPoolin  (None, 21, 3, 3, 256)        0         ['conv_lstm2d_5[0][0]']       \n",
            " g3D)                                                                                             \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 48384)                0         ['max_pooling3d_2[0][0]']     \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 1000)                 4838500   ['flatten_2[0][0]']           \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 256)                  256256    ['dense_8[0][0]']             \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 10)                   2570      ['dense_9[0][0]']             \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 2)                    22        ['dense_10[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 100289416 (382.57 MB)\n",
            "Trainable params: 100236296 (382.37 MB)\n",
            "Non-trainable params: 53120 (207.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "lr = 1e-4"
      ],
      "metadata": {
        "id": "kG5DPb1bT-yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7Y_rlgegUwNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = 'model_checkpoint.h5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,  # Set to True if you only want to save weights\n",
        "    save_freq='epoch',\n",
        "    period=5  # Save every 5 epochs\n",
        ")"
      ],
      "metadata": {
        "id": "OSBL81l_VQL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64295c8-9291-4b9d-fe14-471cc9b788a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_ds,\n",
        "                    validation_data=test_ds,\n",
        "                    epochs=epochs,\n",
        "                    validation_freq=1,\n",
        "                    verbose=1, callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "id": "BgQMng_pUwfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e57e7e9-619b-47df-b927-8dfd0bcffa57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "107/107 [==============================] - 294s 2s/step - loss: 0.6987 - accuracy: 0.4719 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "107/107 [==============================] - 167s 2s/step - loss: 0.6932 - accuracy: 0.4844 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "107/107 [==============================] - 167s 2s/step - loss: 0.6932 - accuracy: 0.4781 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "107/107 [==============================] - 167s 2s/step - loss: 0.6932 - accuracy: 0.4812 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "107/107 [==============================] - 183s 2s/step - loss: 0.6932 - accuracy: 0.4906 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 6/20\n",
            "107/107 [==============================] - 168s 2s/step - loss: 0.6932 - accuracy: 0.4906 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 7/20\n",
            "107/107 [==============================] - 167s 2s/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 8/20\n",
            "107/107 [==============================] - 168s 2s/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "107/107 [==============================] - 177s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "107/107 [==============================] - 188s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 11/20\n",
            "107/107 [==============================] - 168s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 12/20\n",
            "107/107 [==============================] - 177s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 13/20\n",
            "107/107 [==============================] - 167s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 14/20\n",
            "107/107 [==============================] - 178s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 15/20\n",
            "107/107 [==============================] - 189s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 16/20\n",
            "107/107 [==============================] - 167s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 17/20\n",
            "107/107 [==============================] - 167s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "107/107 [==============================] - 167s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "107/107 [==============================] - 177s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "107/107 [==============================] - 183s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds, return_dict=True)"
      ],
      "metadata": {
        "id": "Y8uqML4WUyN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac269ce-c7fd-4a25-9f08-875c9bc2cd33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 11s 390ms/step - loss: 0.6931 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 0.6931478977203369, 'accuracy': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RESNET pretrained\n",
        "pretrained_model = tf.keras.applications.ResNet50(include_top=False,\n",
        "                                                  input_shape=(224, 224, 3),\n",
        "                                                  pooling='avg',\n",
        "                                                  weights='imagenet')"
      ],
      "metadata": {
        "id": "NrCCKjNSp5Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# buang avg pool layer\n",
        "gap_layer_name = 'avg_pool'\n",
        "gap_layer_index = None\n",
        "\n",
        "for i, layer in enumerate(pretrained_model.layers):\n",
        "    if layer.name == gap_layer_name:\n",
        "        gap_layer_index = i\n",
        "        break\n",
        "\n",
        "\n",
        "if gap_layer_index is not None:\n",
        "    model_without_gap = tf.keras.Model(inputs=pretrained_model.input, outputs=pretrained_model.layers[gap_layer_index - 1].output)\n",
        "\n",
        "else:\n",
        "    print(\"GAP layer not found.\")"
      ],
      "metadata": {
        "id": "j66Rplr0p5ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_input_shape = (21, 224, 224, 3)\n",
        "\n",
        "video_input = tf.keras.Input(shape=video_input_shape)\n",
        "time_distributed = TimeDistributed(model_without_gap)(video_input)\n",
        "\n",
        "conv_lstm_output = ConvLSTM2D(filters=256, kernel_size=(3, 3), padding=\"same\", return_sequences=True)(time_distributed)\n",
        "\n",
        "# mhsa_output = MultiHeadAttention(num_heads=8, key_dim=256, value_dim=256)(conv_lstm_output, conv_lstm_output)\n",
        "# attention_time = TimeDistributed(tf.keras.layers.Lambda(lambda x: x))(mhsa_output)\n",
        "\n",
        "# conv_lstm_output2 = ConvLSTM2D(filters=256, kernel_size=(3, 3), padding=\"same\", return_sequences=True)(attention_time)\n",
        "\n",
        "maxpool3d = MaxPooling3D(pool_size=(1,2,2))(conv_lstm_output)\n",
        "\n",
        "flattened = Flatten()(maxpool3d)\n",
        "\n",
        "dense_1 = Dense(1000, activation=\"relu\")(flattened)\n",
        "dense_2 = Dense(256, activation=\"relu\")(dense_1)\n",
        "dense_3 = Dense(10, activation=\"relu\")(dense_2)\n",
        "dense_4 = Dense(2, activation=\"softmax\")(dense_3)\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.Model(inputs=video_input, outputs=dense_4)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "XJAIz6qcUzDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "271e4d14-4160-407a-c2fb-79af14cf9d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 21, 224, 224, 3   0         \n",
            "                             )]                                  \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDi  (None, 21, 7, 7, 2048)    23587712  \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " conv_lstm2d_7 (ConvLSTM2D)  (None, 21, 7, 7, 256)     21234688  \n",
            "                                                                 \n",
            " max_pooling3d_4 (MaxPoolin  (None, 21, 3, 3, 256)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 48384)             0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1000)              48385000  \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 256)               256256    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93466248 (356.55 MB)\n",
            "Trainable params: 93413128 (356.34 MB)\n",
            "Non-trainable params: 53120 (207.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wo2xc46RxwoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = 'model_checkpoint2.h5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,  # Set to True if you only want to save weights\n",
        "    save_freq='epoch',\n",
        "    period=5  # Save every 5 epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHFlOc_4x8Mf",
        "outputId": "70168ff5-c9b6-4fd1-ac20-66aee748911b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_ds,\n",
        "                    validation_data=test_ds,\n",
        "                    epochs=epochs,\n",
        "                    validation_freq=1,\n",
        "                    verbose=1, callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-NtMfWFyChf",
        "outputId": "7d09ef99-9350-4378-9b1a-dbab8c93afab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "107/107 [==============================] - 198s 1s/step - loss: 0.7559 - accuracy: 0.6125 - val_loss: 0.7391 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "107/107 [==============================] - 159s 1s/step - loss: 0.4839 - accuracy: 0.7656 - val_loss: 1.3274 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "107/107 [==============================] - 159s 1s/step - loss: 0.3584 - accuracy: 0.8562 - val_loss: 0.9411 - val_accuracy: 0.5250\n",
            "Epoch 4/20\n",
            "107/107 [==============================] - 159s 1s/step - loss: 0.3072 - accuracy: 0.8875 - val_loss: 1.1976 - val_accuracy: 0.5500\n",
            "Epoch 5/20\n",
            "107/107 [==============================] - 168s 2s/step - loss: 0.2439 - accuracy: 0.9156 - val_loss: 0.9767 - val_accuracy: 0.7375\n",
            "Epoch 6/20\n",
            "107/107 [==============================] - 159s 1s/step - loss: 0.1262 - accuracy: 0.9531 - val_loss: 1.5305 - val_accuracy: 0.6750\n",
            "Epoch 7/20\n",
            "107/107 [==============================] - 159s 1s/step - loss: 0.1300 - accuracy: 0.9469 - val_loss: 0.8788 - val_accuracy: 0.7375\n",
            "Epoch 8/20\n",
            "107/107 [==============================] - 159s 1s/step - loss: 0.0846 - accuracy: 0.9812 - val_loss: 1.4681 - val_accuracy: 0.5875\n",
            "Epoch 9/20\n",
            "107/107 [==============================] - 159s 1s/step - loss: 0.1039 - accuracy: 0.9750 - val_loss: 0.7623 - val_accuracy: 0.7000\n",
            "Epoch 10/20\n",
            "107/107 [==============================] - 177s 2s/step - loss: 0.0580 - accuracy: 0.9812 - val_loss: 1.1509 - val_accuracy: 0.7000\n",
            "Epoch 11/20\n",
            "107/107 [==============================] - 159s 1s/step - loss: 0.1217 - accuracy: 0.9563 - val_loss: 1.4247 - val_accuracy: 0.6375\n",
            "Epoch 12/20\n",
            "107/107 [==============================] - 159s 1s/step - loss: 0.0475 - accuracy: 0.9875 - val_loss: 1.4995 - val_accuracy: 0.6375\n",
            "Epoch 13/20\n",
            "107/107 [==============================] - 160s 1s/step - loss: 0.0227 - accuracy: 0.9906 - val_loss: 2.0509 - val_accuracy: 0.7250\n",
            "Epoch 14/20\n",
            "107/107 [==============================] - 159s 1s/step - loss: 0.0094 - accuracy: 0.9937 - val_loss: 2.0923 - val_accuracy: 0.7125\n",
            "Epoch 15/20\n",
            "107/107 [==============================] - 174s 2s/step - loss: 0.1280 - accuracy: 0.9812 - val_loss: 1.0826 - val_accuracy: 0.6125\n",
            "Epoch 16/20\n",
            "107/107 [==============================] - 159s 1s/step - loss: 0.1230 - accuracy: 0.9594 - val_loss: 1.0225 - val_accuracy: 0.6250\n",
            "Epoch 17/20\n",
            "107/107 [==============================] - 158s 1s/step - loss: 0.2546 - accuracy: 0.9062 - val_loss: 0.6185 - val_accuracy: 0.6875\n",
            "Epoch 18/20\n",
            "107/107 [==============================] - 159s 1s/step - loss: 0.1242 - accuracy: 0.9531 - val_loss: 1.2101 - val_accuracy: 0.6625\n",
            "Epoch 19/20\n",
            "107/107 [==============================] - 160s 1s/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 1.7227 - val_accuracy: 0.6625\n",
            "Epoch 20/20\n",
            "107/107 [==============================] - 179s 2s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8265 - val_accuracy: 0.6625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBl2z_K9yDGF",
        "outputId": "d6f79792-66cd-4fdc-f514-098e865b6d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 9s 340ms/step - loss: 1.8265 - accuracy: 0.6625\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 1.8264859914779663, 'accuracy': 0.6625000238418579}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HNmK0P67yHr3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}